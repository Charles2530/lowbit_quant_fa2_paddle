# InferenceKit
åº”ç”¨äºå¤§è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ä»¥åŠæ¨ç†

## 1. é¡¹ç›®ç»“æ„ç›®å½•
**dataset**: æ•°æ®é›†åŠ è½½

**models**: LLMæ¨¡å‹åŠ è½½ä»¥åŠä¸åŒæ¨ç†æ–¹å¼çš„å®ç°

**reward_models**ï¼š Reward modelçš„æ¨¡å‹åŠ è½½ä»¥åŠæ¨ç†æ–¹å¼å®ç°

**utils**: å­˜å‚¨ã€è¯»å–æ–‡ä»¶çš„å·¥å…·ç±»

**data_config.py**ï¼šé…ç½®è¯„æµ‹æ•°æ®

**model_config.py**ï¼šé…ç½®æ¨¡å‹

**inference.py**: æ¨ç†benchmark

**main.py**ï¼šæ¨ç†benchmarkçš„ä¸»ç¨‹åºå…¥å£

**play.py**ï¼šå¤šè½®å¯¹è¯çš„ä¸»ç¨‹åºå…¥å£

## è¿è¡Œç¯å¢ƒ
```
pip install -r requirements.txt
```

## 2. è¿è¡Œ
æ ¹æ®éœ€æ±‚çš„ä¸åŒè¿è¡Œä¸åŒçš„è„šæœ¬ã€‚
**è¯„æµ‹benchmark**ï¼šç”¨äºæ‰¹é‡è¿›è¡Œè¯„æµ‹
**å¤šè½®å¯¹è¯**ï¼šé€šè¿‡åœ¨å‘½ä»¤è¡Œè¾“å…¥æ–‡æœ¬å’Œæ¨¡å‹å¯¹è¯

### è¯„æµ‹benchmark
```
cd scripts
bash run.sh
```
**å‚æ•°ä»‹ç»ï¼š**
work_dir: ç»“æœä¿å­˜çš„è·¯å¾„
MODEL_NAME: è¯„æµ‹çš„æ¨¡å‹åå­—ï¼Œå¿…é¡»åœ¨model_config.pyä¸­è¿›è¡Œé…ç½®ã€‚
MODEL_PATH: è¯„æµ‹çš„æ¨¡å‹çš„æƒé‡è·¯å¾„
DATASET_NAME: è¯„æµ‹çš„benchmarkçš„åå­—ï¼Œå¿…é¡»åœ¨data_config.pyä¸­è¿›è¡Œé…ç½®ã€‚

### å¤šè½®å¯¹è¯
```
cd scripts
bash dialogue.sh
```
**å‚æ•°ä»‹ç»ï¼š**
model: LLMçš„æ¨¡å‹åç§°ï¼Œè¦å‡ºç°åœ¨model_config.pyçš„é…ç½®æ–‡ä»¶ä¸­ã€‚
model_path: LLMçš„æ¨¡å‹è·¯å¾„ã€‚
reward_model: å¥–åŠ±æ¨¡å‹çš„åç§°ï¼ŒåŒæ ·éœ€è¦åœ¨model_config.pyä¸­è¿›è¡Œé…ç½®
reward_model_path: å¥–åŠ±æ¨¡å‹çš„æœ¬åœ°è·¯å¾„

## 3. åŠ å…¥æ¨¡å‹

### åŠ å…¥LLM
- step 1 åœ¨modelsä¸­å®ç°ç›¸åº”çš„LLMçš„åˆå§‹åŒ–ä»¥åŠæ¨ç†å‡½æ•°ï¼ˆè‡³å°‘è¦å®ç°vanilla_generate,ä¸€èˆ¬çœ‹å®˜æ–¹çš„è°ƒç”¨æ–‡æ¡£ï¼‰ã€‚
- step 2 åœ¨models çš„__init__.pyä¸­importç›¸å…³çš„ç±»ã€‚
- step 3 åœ¨model_config.pyä¸­æ·»åŠ æ¨¡å‹çš„ç›¸å…³é…ç½®ã€‚åœ¨sft_model_groupsä¸­åŠ å…¥æ¨¡å‹çš„åç§°ï¼ˆä¹Ÿå°±æ˜¯å­—å…¸çš„é”®ï¼Œæœ€å¥½ç®€æ´æ˜äº†ï¼‰ï¼Œå€¼ä¸ºpartialåŒ…è£¹çš„æ¨¡å‹çš„ç±»åä»¥åŠæ¨¡å‹çš„æœ¬åœ°è·¯å¾„ã€‚

### åŠ å…¥Reward Model
- step 1 åœ¨reward_modelsä¸­å®ç°ç›¸åº”çš„reward modelçš„åˆå§‹åŒ–å‡½æ•°ä»¥åŠè®¡ç®—å¾—åˆ†çš„å‡½æ•°ï¼ˆscoreï¼‰ã€‚ä¸€èˆ¬æ€ä¹ˆåŠ è½½æ¨¡å‹å’Œè®¡ç®—scoreæŸ¥çœ‹å®˜æ–¹çš„è°ƒç”¨æ–‡æ¡£ã€‚
- step 2 åœ¨modelsçš„__init__.pyä¸­import ç›¸å…³çš„ç±»ã€‚
- step 3 åœ¨model_config.pyä¸­æ·»åŠ æ¨¡å‹çš„ç›¸å…³é…ç½®ã€‚å…·ä½“é…ç½®åŒLLMğŸ‘†


## 4. åŠ å…¥è¯„æµ‹æ•°æ®é›†
- step 1 åœ¨datasetä¸­å®ç°æ•°æ®é›†çš„åŠ è½½å‡½æ•°ã€‚è¦æ±‚ï¼šæ•°æ®é›†ä¸­å¿…é¡»æœ‰çš„å­—æ®µï¼šindexå’Œinputã€‚indexæ ‡æ˜è¯¥æ ·æœ¬çš„å”¯ä¸€æ ‡è¯†åºå·ï¼Œinputä»£è¡¨æ¨¡å‹çš„è¾“å…¥ã€‚æ•°æ®çš„æ ¼å¼å‚ç…§example_dataset.json ã€‚ å¦‚æœéœ€è¦è®¡ç®—è¯„ä»·æŒ‡æ ‡ï¼Œè¯·åœ¨å¯¹åº”çš„datasetçš„ç±»ä¸­å®ç°evaluateæ–¹æ³•ã€‚
- step 2 åœ¨dataset çš„__init__.pyä¸­importç›¸å…³çš„ç±»ã€‚
- step 3 åœ¨data_config.pyä¸­é…ç½®ç›¸å…³çš„ä¿¡æ¯ã€‚supported_datasetä¸­çš„é”®ä¸ºæ•°æ®é›†çš„åç§°ï¼ˆæœ€å¥½ç®€æ´æ˜äº†ï¼‰ï¼Œvalueä¸ºç”¨partialåŒ…è£¹çš„å¯¹åº”çš„æ•°æ®é›†çš„ç±»ä»¥åŠdataset_nameï¼ˆå’Œé”®ä¸€è‡´å°±è¡Œï¼‰å’Œdataset_pathï¼ˆæ•°æ®é›†çš„è·¯å¾„ï¼‰ã€‚å‚è§simpledataset.py


## æ¨¡å‹é…ç½®
- Config è¯»å–ä¼˜å…ˆçº§: runtime arguments > command arguments(only generation config) > model arguments > config file > model default > default

## 2024/11/02 Update @ wenbin wang
1. å°†wentaoä¿®æ”¹çš„ä»£ç åˆå¹¶åˆ°mainåˆ†æ”¯
2. å¢åŠ benchmark è¯„æµ‹çš„æ¥å£å‡½æ•° evaluate
3. å°†benchmarkæ•°æ®è¿ç§»åˆ°æ–‡ä»¶å¤¹benchmarkä¸­

## 2024/11/07 Updata @ Wentao Jiang
1. å¢åŠ Vanilla MCTSä»£ç ï¼Œåœ¨50æ¡æ•°æ®ä¸Šæµ‹è¯•

## 2024/11/07 Update @ Wenjie Wu & Tong Yu
1. å¢åŠ äº†basedatasetçš„evaluateå‡½æ•°ï¼Œå¯ä»¥å¯¹æ¨ç†ç»“æœè¿›è¡Œè¯„æµ‹ã€‚grader.pyä¸­å¢åŠ äº†æ•°å­¦è¡¨è¾¾å¼è¯„æµ‹çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ•°å­¦è¡¨è¾¾å¼ç›¸ç­‰è¯„æµ‹å’Œæ•°å­¦è¡¨è¾¾å¼ç›¸ä¼¼åº¦è¯„æµ‹ã€‚
2. ä¿®æ”¹äº† gsm8k å’Œ math dataset çš„promptï¼Œ æç¤ºæ¨¡å‹å°†ç­”æ¡ˆæ”¾åœ¨ `$\boxed{}$` ä¸­ï¼Œæ–¹ä¾¿è¯„æµ‹ã€‚

## 2024/11/08 Update @ Tong Yu
1. å¢åŠ äº†compareæ¥å£ï¼Œå¯¹æ¯”ä¸¤ä¸ªç”Ÿæˆç»“æœA,Bï¼Œé‡ç‚¹è¾“å‡ºAå¯¹Bé”™ã€Aé”™Bå¯¹ã€ABå‡é”™çš„æƒ…å†µ
2. é’ˆå¯¹promptæœ‰box{}çš„æç¤ºè¯ï¼ŒåŒ¹é…æ‰€æœ‰boxï¼Œåªè¦å­˜åœ¨æ­£ç¡®å›ç­”çš„å°±è®¤ä¸ºæ­£ç¡®

## 2024/11/11 Update @ Wenjie Wu & Tong Yu & Wentao Jiang
1. å¢åŠ Best of Næ–¹æ³•
2. å¢åŠ Beam Searchæ–¹æ³•
3. é‡æ„generationæ¨¡å—ä»£ç 

## 2024/11/12 Update @ Wenjie Wu & Tong Yu
1. å¢åŠ majority_vote, min_vote, last_voteçš„æŠ•ç¥¨æ–¹æ³•
2. ä¼˜åŒ–äº†resultæ–‡ä»¶çš„ä¿å­˜æ ¼å¼ï¼Œç°ä¸ºdataset_name-cot_method-voting_method.jsonæˆ–dataset_name-cot_method.json


## TODO
1. ~~å®æ—¶ç”Ÿæˆå®éªŒç»“æœï¼Œè€Œä¸æ˜¯åœ¨è¿›è¡Œå®Œæ‰€æœ‰æ¨ç†åå†ç”Ÿæˆ~~
2. ~~æ¨¡å‹é…ç½®ç®¡ç†ä»¥åŠå®éªŒç»“æœç®¡ç†ï¼šresultæ–‡ä»¶å¤¹ä¸­å­æ–‡ä»¶ä»£è¡¨æ•°æ®é›†ï¼Œå†ä¸‹çº§æ–‡ä»¶å¤¹ä»£è¡¨å„æ•°æ®é›†ä¸‹è¿›è¡Œçš„å®éªŒï¼Œéœ€è¦ä»¥model+reward_model+exp_nameå‘½åï¼Œå…¶ä¸­åŒ…æ‹¬configå’Œå®éªŒç»“æœ~~
3. å°†å…¶å’Œä»“åº“understanding-o1/understanding-o1åˆå¹¶
4. ~~å¢åŠ  chat templateï¼Œå½“å‰çš„æ¨¡æ¿ä¸å¤ªå¥½~~
5. ~~ç†é¡ºæ¨¡å‹é€»è¾‘ï¼Œé‡æ„models.llama3æ–‡ä»¶ï¼Œå°†å…¶æ”¹æˆé€šç”¨çš„huggingface modelï¼Œä¸ºæ¯ä¸ªæ¨¡å‹ä¿å­˜é…ç½®æ–‡ä»¶~~
6. ~~åˆ†å‰²ç¬¦ä½œä¸ºå„ä¸ªæ¨¡å‹çš„é…ç½®ï¼ŒåŒ…æ‹¬modelå’Œreward model~~
7. ~~åˆ†ç¦»inferenceå’Œevaluateä»£ç ï¼Œä¸€ä¸ªç”¨äºinferenceå®éªŒï¼Œä¸€ä¸ªç”¨å®éªŒç”Ÿæˆç»“æœæ¥è¯„ä¼°æ€§èƒ½~~
8. ~~modelå’Œreward_modelæä¾›é»˜è®¤è·¯å¾„ï¼Œæ”¯æŒä»…é€šè¿‡åç§°è°ƒç”¨~~
9. ~~å¢åŠ Best of N, Beam Searchçš„CoTæœç´¢æ–¹å¼~~
10. ~~logger åŠŸèƒ½~~
11. ~~Resume åŠŸèƒ½~~
12. ~~å¤šVote~~
13. æ¨¡å‹åˆ†ç‰‡
14. Flash Attention
15. Token-Levelæœç´¢æ¡†æ¶å®ç°
